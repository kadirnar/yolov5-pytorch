{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch-Yolov5.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"19NnAgpZBn3idhoS6_BnRn7RVTXAEzW9U","authorship_tag":"ABX9TyNu1zHw7rehAq7cUsRCmMVx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FwVK-vBAqgjN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618155164005,"user_tz":-180,"elapsed":1701,"user":{"displayName":"GÃ–KSENÄ°N Ä°HA","photoUrl":"","userId":"07662628698708789801"}},"outputId":"5f1cb134-1df6-4a41-df37-fa7a880d196e"},"source":["%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Yz7UYp8pZ9R"},"source":["!pip install yolov5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oC6dHc9fqycC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637245752247,"user_tz":-180,"elapsed":479,"user":{"displayName":"Kadir Nar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07662628698708789801"}},"outputId":"b5ef5245-c8c5-4cbb-f307-d6cd5c420a64"},"source":["cd /content/drive/MyDrive/yolo/pytorch-yolov5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/yolo/pytorch-yolov5\n"]}]},{"cell_type":"code","metadata":{"id":"IVJdRptuqylD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637245773015,"user_tz":-180,"elapsed":17822,"user":{"displayName":"Kadir Nar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07662628698708789801"}},"outputId":"f430db33-c938-4d51-b44e-4b7a283df274"},"source":["!tar -xzvf \"cudnn-10.0-linux-x64-v7.6.5.32.tgz\" -C /usr/local/\n","!chmod a+r /usr/local/cuda/include/cudnn.h\n","!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda/include/cudnn.h\n","cuda/NVIDIA_SLA_cuDNN_Support.txt\n","cuda/lib64/libcudnn.so\n","cuda/lib64/libcudnn.so.7\n","cuda/lib64/libcudnn.so.7.6.5\n","cuda/lib64/libcudnn_static.a\n","#define CUDNN_MAJOR 7\n","#define CUDNN_MINOR 6\n","#define CUDNN_PATCHLEVEL 5\n","--\n","#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n","\n","#include \"driver_types.h\"\n"]}]},{"cell_type":"code","metadata":{"id":"aN8UBm3ATfa1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637248127390,"user_tz":-180,"elapsed":2280935,"user":{"displayName":"Kadir Nar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07662628698708789801"}},"outputId":"f82d4ce4-db67-4f1b-a2a4-3ee998af5837"},"source":["!yolov5 train --data data.yaml --weights 'yolov5s.pt' --batch-size 16 --epochs 10"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, mmdet_tags=False, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, neptune_token=, neptune_project=\n","YOLOv5 ðŸš€ 2021-11-18 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0032, lrf=0.12, momentum=0.843, weight_decay=0.00036, warmup_epochs=2.0, warmup_momentum=0.5, warmup_bias_lr=0.05, box=0.0296, cls=0.243, cls_pw=0.631, obj=0.301, obj_pw=0.911, iou_t=0.2, anchor_t=2.91, fl_gamma=0.0, hsv_h=0.0138, hsv_s=0.664, hsv_v=0.464, degrees=0.373, translate=0.245, scale=0.898, shear=0.602, perspective=0.0, flipud=0.00856, fliplr=0.5, mosaic=1.0, mixup=0.243, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs\n","\u001b[34m\u001b[1mNeptune AI: \u001b[0mrun 'pip install neptune-client' to automatically track and visualize YOLOv5 ðŸš€ runs\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n","  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n","  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n","  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n","  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n","  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n","  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n","  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n","  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n"," 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n"," 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n"," 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n"," 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n"," 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n"," 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n"," 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n"," 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  yolov5.models.yolo.Detect               [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","Scaled weight_decay = 0.00036\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'datasets/labels/train' images and labels...1354 found, 0 missing, 0 empty, 0 corrupted: 100% 1354/1354 [02:42<00:00,  8.34it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: datasets/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val' images and labels...582 found, 0 missing, 0 empty, 0 corrupted: 100% 582/582 [01:08<00:00,  8.45it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: datasets/labels/val.cache\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.83, Best Possible Recall (BPR) = 0.9962\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp2\u001b[0m\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/9     3.23G     0.069   0.01481   0.01106       128       640: 100% 85/85 [02:54<00:00,  2.05s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:32<00:00,  1.71s/it]\n","                 all        582       2993    0.00873     0.0898    0.00415   0.000917\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/9     5.42G   0.06353   0.01539   0.01096       143       640: 100% 85/85 [02:51<00:00,  2.02s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:29<00:00,  1.56s/it]\n","                 all        582       2993      0.021      0.116    0.00925    0.00215\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/9     5.42G   0.05725   0.01735   0.01054        86       640: 100% 85/85 [02:50<00:00,  2.01s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:27<00:00,  1.44s/it]\n","                 all        582       2993     0.0711      0.198     0.0334    0.00951\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/9     5.42G   0.05119   0.01863   0.01025        87       640: 100% 85/85 [02:51<00:00,  2.02s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:25<00:00,  1.32s/it]\n","                 all        582       2993      0.225      0.283      0.125     0.0495\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/9     5.42G   0.04563    0.0193  0.009894       155       640: 100% 85/85 [02:48<00:00,  1.98s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:25<00:00,  1.32s/it]\n","                 all        582       2993      0.247      0.374      0.171     0.0807\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       5/9     5.42G   0.04178   0.01841   0.00969       103       640: 100% 85/85 [02:51<00:00,  2.02s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:23<00:00,  1.25s/it]\n","                 all        582       2993      0.284      0.359      0.201      0.101\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       6/9     5.42G   0.03947   0.01803  0.009607        51       640: 100% 85/85 [02:53<00:00,  2.04s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:24<00:00,  1.27s/it]\n","                 all        582       2993      0.312      0.378       0.23      0.119\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       7/9     5.42G   0.03747    0.0171  0.009416        80       640: 100% 85/85 [02:52<00:00,  2.03s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:23<00:00,  1.24s/it]\n","                 all        582       2993      0.323      0.398      0.253       0.13\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       8/9     5.42G   0.03603   0.01698  0.009221       108       640: 100% 85/85 [02:51<00:00,  2.02s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:22<00:00,  1.20s/it]\n","                 all        582       2993      0.353      0.395      0.278      0.157\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       9/9     5.42G    0.0353   0.01685  0.009243        88       640: 100% 85/85 [02:50<00:00,  2.00s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:23<00:00,  1.22s/it]\n","                 all        582       2993       0.35      0.411      0.286      0.161\n","\n","10 epochs completed in 0.554 hours.\n","Optimizer stripped from runs/train/exp2/weights/last.pt, 14.4MB\n","Optimizer stripped from runs/train/exp2/weights/best.pt, 14.4MB\n","\n","Validating runs/train/exp2/weights/best.pt...\n","Fusing layers... \n","Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 19/19 [00:23<00:00,  1.23s/it]\n","                 all        582       2993      0.349      0.415      0.287      0.162\n","               Apple        582       1095      0.356      0.341      0.263      0.169\n","              Orange        582       1898      0.342      0.489      0.312      0.154\n","Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3KvcmLph_yZ","executionInfo":{"status":"ok","timestamp":1637248848026,"user_tz":-180,"elapsed":7277,"user":{"displayName":"Kadir Nar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07662628698708789801"}},"outputId":"8022b8b3-2f65-4c3e-cdf1-e660e4207b3a"},"source":["!yolov5 detect --source images/  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv5 ðŸš€ 2021-11-18 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","Fusing layers... \n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 270 layers, 7235389 parameters, 0 gradients\n","image 1/5 /content/drive/My Drive/yolo/pytorch-yolov5/images/1.jpg: 448x640 8 apples, Done. (0.030s)\n","image 2/5 /content/drive/My Drive/yolo/pytorch-yolov5/images/2.jpg: 480x640 1 fire hydrant, 78 apples, Done. (0.032s)\n","image 3/5 /content/drive/My Drive/yolo/pytorch-yolov5/images/3.jpg: 480x640 74 apples, 1 orange, Done. (0.031s)\n","image 4/5 /content/drive/My Drive/yolo/pytorch-yolov5/images/deneme.jpg: 480x640 32 apples, 17 oranges, Done. (0.031s)\n","image 5/5 /content/drive/My Drive/yolo/pytorch-yolov5/images/elma-agÌ†acÄ±.jpg: 384x640 67 apples, 1 orange, Done. (0.030s)\n","Speed: 0.6ms pre-process, 30.7ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}]}]}